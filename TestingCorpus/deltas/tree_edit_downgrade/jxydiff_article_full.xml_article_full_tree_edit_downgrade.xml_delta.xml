<?xml version="1.0"?><delta><Deleted pos="0:1:3:8">
    </Deleted><Deleted move="yes" pos="0:1:3:7:5"><sec>
        <title>Flow Monitoring</title>
        <p>River systems and stream flows can be monitored by remotely integrating the techniques of water body observation, vegetation mapping, DEM generation, and hydrological modelling. Satellite sensors in the visible, infrared, and microwave ranges are currently used to monitor rivers and to delineate flood zones [<xref rid="B136-remotesensing-10-00641" ref-type="bibr">136</xref>,<xref rid="B137-remotesensing-10-00641" ref-type="bibr">137</xref>,<xref rid="B138-remotesensing-10-00641" ref-type="bibr">138</xref>]. These methods are generally used only over large rivers or areas of inundation in order to detect changes at the pixel level. UAS can describe river dynamics, but with a level of detail that is several orders of magnitude greater and can enable distributed flow measurements over any river system and in difficult-to-access environments.</p>
        <p>In this context, the integration of UAS imagery and optical velocimetry techniques has enabled full remote kinematic characterization of water bodies and surface flows. Optical techniques, such as Large-Scale Particle Image Velocimetry (LSPIV, [<xref rid="B139-remotesensing-10-00641" ref-type="bibr">139</xref>]) and Particle Tracking Velocimetry (PTV [<xref rid="B140-remotesensing-10-00641" ref-type="bibr">140</xref>]), are efficient yet nonintrusive flow visualization methods that yield a spatially distributed estimation of the surface flow velocity field based on the similarity of image sequences. Proof-of-concept experiments have demonstrated the feasibility of applying LSPIV from manned aerial systems to monitor flood events [<xref rid="B141-remotesensing-10-00641" ref-type="bibr">141</xref>,<xref rid="B142-remotesensing-10-00641" ref-type="bibr">142</xref>]. More recently, videos recorded from a UAS have been analyzed with LSPIV to reconstruct surface flow velocity fields of natural stream reaches [<xref rid="B143-remotesensing-10-00641" ref-type="bibr">143</xref>,<xref rid="B144-remotesensing-10-00641" ref-type="bibr">144</xref>]. This provides a detailed Lagrangian insight into river dynamics that is valuable in calibrating numerical models. </p>
        <p>Most of these experimental observations entail a low-cost UAS hovering above the region of interest for a few seconds (the observation time should be adjusted to the flow velocity and camera acquisition frequency). An RGB camera is typically mounted onboard and installed with its optical axis perpendicular to the captured field of view to circumvent orthorectification [<xref rid="B145-remotesensing-10-00641" ref-type="bibr">145</xref>]. To facilitate remote photometric calibration, Tauro et al. [<xref rid="B145-remotesensing-10-00641" ref-type="bibr">145</xref>] adopted a UAS equipped with a system of four lasers that focus points at known distances in the field of view. In several experimental settings, the accuracy of surface flow velocity estimations from UAS was found to be comparable to (or even better than) that of traditional ground-based LSPIV configurations [<xref rid="B146-remotesensing-10-00641" ref-type="bibr">146</xref>]. In fact, compared to fixed implementations, UAS enable capture of larger fields of view with a diffuse rather than direct illumination. Such optical image velocimetry techniques can measure flow velocity fields over extended regions rather than pointwise, and at temporal resolutions comparable to or even better than Acoustic Doppler Velocimetry (ADV) based on the presence of detectable features on the water surface [<xref rid="B147-remotesensing-10-00641" ref-type="bibr">147</xref>].</p>
        <p>In this context, UAS technology is expected to considerably aid in flood monitoring and mapping. In fact, flood observation is a considerable challenge for space-borne passive imagery, mostly due to the presence of dense cloud cover, closed vegetation canopies, and the satellite revisit time and viewing angle [<xref rid="B133-remotesensing-10-00641" ref-type="bibr">133</xref>,<xref rid="B148-remotesensing-10-00641" ref-type="bibr">148</xref>]. Although SAR satellite sensors (e.g., Sentinel-1, TerraSAR-X, RADARSAT-2) can overcome these visibility limitations, they are unable to provide the submeter-level spatial resolution necessary for detailed understanding of flood routing and susceptibility. Applying UAS with an appropriate flight mode may overcome some of these issues, allowing for rapid and safe monitoring of inundations and measurement of flood hydrological parameters [<xref rid="B149-remotesensing-10-00641" ref-type="bibr">149</xref>]. This is possible also because most platforms are quite stable in windy conditions (less than 5 m/s in the case of multirotors).</p>
        <p>Challenges for the widespread adoption and incorporation of UAS for flow monitoring have commonalities with both agricultural and ecosystems monitoring, including the coupling of measurements from multiple sensors through accurate and efficient processing workflows. Specific to streamflow measurement, these include (i) optimization of SfM workflows to enable extraction of terrestrial and subsurface topographies through accurate image registration using automatic or direct georeferencing techniques; (ii) the determination of water levels through image- (e.g., SfM; [<xref rid="B150-remotesensing-10-00641" ref-type="bibr">150</xref>]), sensor- (e.g., laser, radar; [<xref rid="B151-remotesensing-10-00641" ref-type="bibr">151</xref>]), and turbulence-derived metrics [<xref rid="B152-remotesensing-10-00641" ref-type="bibr">152</xref>]; and (iii) the derivation of flow velocities through appropriate techniques (e.g., PIV/PTV), based on the characteristics of flow, duration of observation, seeding density, etc.). The task of combining these data and developing workflows that are capable of rapidly producing synoptic river flow measurements based on the range of available inputs is an ongoing challenge to ensure UAS-based measurements are able to fully support water resource management and civil protection agencies.</p>
        <p>In this context, hyperspectral sensors can also be used to extend the range of water monitoring applications. Potential examples include sediment concentration, chlorophyll distribution, blooming algae status, submerged vegetation mapping, bathymetry, and chemical and organic waste contaminations [<xref rid="B153-remotesensing-10-00641" ref-type="bibr">153</xref>,<xref rid="B154-remotesensing-10-00641" ref-type="bibr">154</xref>].</p>
      </sec></Deleted><Deleted move="yes" pos="0:1:3:7:2">
      </Deleted><Deleted move="yes" pos="0:1:3:7:0">
      </Deleted><Deleted pos="0:1:3:7"><sec id="sec4-remotesensing-10-00641"><title>4. River Systems and Floods</title><p>Satellite data are widely used to monitor natural hazards (e.g., floods, earthquakes, volcanic eruptions, wildfire, etc.) at national and international scales [<xref rid="B131-remotesensing-10-00641" ref-type="bibr">131</xref>]. This popularity is due to their wide coverage, spectral resolution, safety, and rate of update [<xref rid="B132-remotesensing-10-00641" ref-type="bibr">132</xref>,<xref rid="B133-remotesensing-10-00641" ref-type="bibr">133</xref>]. Nevertheless, UAS have also been adopted for rapid assessment following natural extreme events and in the context of humanitarian relief and infrastructure assessment [<xref rid="B28-remotesensing-10-00641" ref-type="bibr">28</xref>]. According to Quaritsch et al. [<xref rid="B134-remotesensing-10-00641" ref-type="bibr">134</xref>], UAS should be utilized as a component of a network of sensors for natural disaster management. Although there are a number of technological barriers, which must be overcome before UAS can be utilized in a more automated and coordinated manner, their potential for disaster response is significant [<xref rid="B135-remotesensing-10-00641" ref-type="bibr">135</xref>]. Given the UAS potential, we expect significant advances in the fields of hydrology, geomorphology, and hydraulics, where there is a significant opportunity for the use of UAS for monitoring river systems, overland flows, or even urban floods.</p>
      
    </sec></Deleted><Inserted move="yes" pos="0:1:3:5:8">
      </Inserted><Inserted pos="0:1:3:5:9"><sec id="sec3dot3-remotesensing-10-00641">
        <title>4. River Systems and Floods</title>
        <p>Satellite data are widely used to monitor natural hazards (e.g., floods, earthquakes, volcanic eruptions, wildfire, etc.) at national and international scales [<xref rid="B131-remotesensing-10-00641" ref-type="bibr">131</xref>]. This popularity is due to their wide coverage, spectral resolution, safety, and rate of update [<xref rid="B132-remotesensing-10-00641" ref-type="bibr">132</xref>,<xref rid="B133-remotesensing-10-00641" ref-type="bibr">133</xref>]. Nevertheless, UAS have also been adopted for rapid assessment following natural extreme events and in the context of humanitarian relief and infrastructure assessment [<xref rid="B28-remotesensing-10-00641" ref-type="bibr">28</xref>]. According to Quaritsch et al. [<xref rid="B134-remotesensing-10-00641" ref-type="bibr">134</xref>], UAS should be utilized as a component of a network of sensors for natural disaster management. Although there are a number of technological barriers, which must be overcome before UAS can be utilized in a more automated and coordinated manner, their potential for disaster response is significant [<xref rid="B135-remotesensing-10-00641" ref-type="bibr">135</xref>]. Given the UAS potential, we expect significant advances in the fields of hydrology, geomorphology, and hydraulics, where there is a significant opportunity for the use of UAS for monitoring river systems, overland flows, or even urban floods.</p>
      </sec></Inserted><Inserted move="yes" pos="0:1:3:5:10">
      </Inserted><Inserted move="yes" pos="0:1:3:5:11"><sec>
        <title>Flow Monitoring</title>
        <p>River systems and stream flows can be monitored by remotely integrating the techniques of water body observation, vegetation mapping, DEM generation, and hydrological modelling. Satellite sensors in the visible, infrared, and microwave ranges are currently used to monitor rivers and to delineate flood zones [<xref rid="B136-remotesensing-10-00641" ref-type="bibr">136</xref>,<xref rid="B137-remotesensing-10-00641" ref-type="bibr">137</xref>,<xref rid="B138-remotesensing-10-00641" ref-type="bibr">138</xref>]. These methods are generally used only over large rivers or areas of inundation in order to detect changes at the pixel level. UAS can describe river dynamics, but with a level of detail that is several orders of magnitude greater and can enable distributed flow measurements over any river system and in difficult-to-access environments.</p>
        <p>In this context, the integration of UAS imagery and optical velocimetry techniques has enabled full remote kinematic characterization of water bodies and surface flows. Optical techniques, such as Large-Scale Particle Image Velocimetry (LSPIV, [<xref rid="B139-remotesensing-10-00641" ref-type="bibr">139</xref>]) and Particle Tracking Velocimetry (PTV [<xref rid="B140-remotesensing-10-00641" ref-type="bibr">140</xref>]), are efficient yet nonintrusive flow visualization methods that yield a spatially distributed estimation of the surface flow velocity field based on the similarity of image sequences. Proof-of-concept experiments have demonstrated the feasibility of applying LSPIV from manned aerial systems to monitor flood events [<xref rid="B141-remotesensing-10-00641" ref-type="bibr">141</xref>,<xref rid="B142-remotesensing-10-00641" ref-type="bibr">142</xref>]. More recently, videos recorded from a UAS have been analyzed with LSPIV to reconstruct surface flow velocity fields of natural stream reaches [<xref rid="B143-remotesensing-10-00641" ref-type="bibr">143</xref>,<xref rid="B144-remotesensing-10-00641" ref-type="bibr">144</xref>]. This provides a detailed Lagrangian insight into river dynamics that is valuable in calibrating numerical models. </p>
        <p>Most of these experimental observations entail a low-cost UAS hovering above the region of interest for a few seconds (the observation time should be adjusted to the flow velocity and camera acquisition frequency). An RGB camera is typically mounted onboard and installed with its optical axis perpendicular to the captured field of view to circumvent orthorectification [<xref rid="B145-remotesensing-10-00641" ref-type="bibr">145</xref>]. To facilitate remote photometric calibration, Tauro et al. [<xref rid="B145-remotesensing-10-00641" ref-type="bibr">145</xref>] adopted a UAS equipped with a system of four lasers that focus points at known distances in the field of view. In several experimental settings, the accuracy of surface flow velocity estimations from UAS was found to be comparable to (or even better than) that of traditional ground-based LSPIV configurations [<xref rid="B146-remotesensing-10-00641" ref-type="bibr">146</xref>]. In fact, compared to fixed implementations, UAS enable capture of larger fields of view with a diffuse rather than direct illumination. Such optical image velocimetry techniques can measure flow velocity fields over extended regions rather than pointwise, and at temporal resolutions comparable to or even better than Acoustic Doppler Velocimetry (ADV) based on the presence of detectable features on the water surface [<xref rid="B147-remotesensing-10-00641" ref-type="bibr">147</xref>].</p>
        <p>In this context, UAS technology is expected to considerably aid in flood monitoring and mapping. In fact, flood observation is a considerable challenge for space-borne passive imagery, mostly due to the presence of dense cloud cover, closed vegetation canopies, and the satellite revisit time and viewing angle [<xref rid="B133-remotesensing-10-00641" ref-type="bibr">133</xref>,<xref rid="B148-remotesensing-10-00641" ref-type="bibr">148</xref>]. Although SAR satellite sensors (e.g., Sentinel-1, TerraSAR-X, RADARSAT-2) can overcome these visibility limitations, they are unable to provide the submeter-level spatial resolution necessary for detailed understanding of flood routing and susceptibility. Applying UAS with an appropriate flight mode may overcome some of these issues, allowing for rapid and safe monitoring of inundations and measurement of flood hydrological parameters [<xref rid="B149-remotesensing-10-00641" ref-type="bibr">149</xref>]. This is possible also because most platforms are quite stable in windy conditions (less than 5 m/s in the case of multirotors).</p>
        <p>Challenges for the widespread adoption and incorporation of UAS for flow monitoring have commonalities with both agricultural and ecosystems monitoring, including the coupling of measurements from multiple sensors through accurate and efficient processing workflows. Specific to streamflow measurement, these include (i) optimization of SfM workflows to enable extraction of terrestrial and subsurface topographies through accurate image registration using automatic or direct georeferencing techniques; (ii) the determination of water levels through image- (e.g., SfM; [<xref rid="B150-remotesensing-10-00641" ref-type="bibr">150</xref>]), sensor- (e.g., laser, radar; [<xref rid="B151-remotesensing-10-00641" ref-type="bibr">151</xref>]), and turbulence-derived metrics [<xref rid="B152-remotesensing-10-00641" ref-type="bibr">152</xref>]; and (iii) the derivation of flow velocities through appropriate techniques (e.g., PIV/PTV), based on the characteristics of flow, duration of observation, seeding density, etc.). The task of combining these data and developing workflows that are capable of rapidly producing synoptic river flow measurements based on the range of available inputs is an ongoing challenge to ensure UAS-based measurements are able to fully support water resource management and civil protection agencies.</p>
        <p>In this context, hyperspectral sensors can also be used to extend the range of water monitoring applications. Potential examples include sediment concentration, chlorophyll distribution, blooming algae status, submerged vegetation mapping, bathymetry, and chemical and organic waste contaminations [<xref rid="B153-remotesensing-10-00641" ref-type="bibr">153</xref>,<xref rid="B154-remotesensing-10-00641" ref-type="bibr">154</xref>].</p>
      </sec></Inserted></delta>