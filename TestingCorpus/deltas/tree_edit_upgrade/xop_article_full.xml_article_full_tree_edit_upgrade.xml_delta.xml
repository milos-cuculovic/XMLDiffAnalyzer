<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<article xmlns:erc="http://ercato.com/xmlns/ErcatoCore" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
      
    <front erc:inherit="expand"/>
      
    <body>
            
        <sec erc:inherit="expand"/>
            
        <sec erc:inherit="expand">
                  
            <sec id="sec2dot3-remotesensing-10-00641">
                        
                <title>2.3. Software</title>
                        
                <p>
                    Alongside sensor technological developments, low-cost (and particularly open source) software has been vital in enabling the growth in UAS for environmental and other applications. UAS-based photogrammetry can produce products of a similar accuracy to those achievable through manned airborne systems [
                    <xref ref-type="bibr" rid="B35-remotesensing-10-00641">35</xref>
                    ]. This has been underpinned by the development of SfM software, which offers a user-friendly and low-cost alternative to conventional digital photogrammetric processing. This includes proprietary structure-from-motion (SfM) software such as Agisoft Photoscan and Pix4D, which is significantly more affordable than most conventional photogrammetric software. Moreover, there has also been development of open source SfM software, including VisualSfM, Bundler, Apero-MicMac, OpenDroneMap, etc. Nevertheless, although different and efficient software solutions are available, the computational cost of the elaboration is critical and it can require several days of data processing. Cloud-based platforms such as DroneDeploy or DroneMapper offer the possibility to integrate and share aerial data, but also to derive orthomosaics with light processing workloads. While this has made photogrammetry more accessible to nonexperts, quantification of uncertainty remains an ongoing challenge [
                    <xref ref-type="bibr" rid="B59-remotesensing-10-00641">59</xref>
                    ]. This is because SfM relaxes some of the conventional expectations in terms of image block geometry and data acquisition.
                </p>
                      
            </sec>
                
        </sec>
            
        <sec>
                  
            <title>3. Monitoring Agricultural and Natural Ecosystems</title>
                  
            <p>
                Natural and agricultural ecosystems are influenced by climatic forcing, physical characteristics, and management practices that are highly variable in both time and space. Moreover, vegetation state changes can often occur within a short period of time [
                <xref rid="B60-remotesensing-10-00641">60</xref>
                ,
                <xref rid="B61-remotesensing-10-00641">61</xref>
                ] due to unfavorable growing conditions or climatic extremes (e.g., heat waves, heavy storms, etc.). Therefore, in order to capture such features, monitoring systems need to provide accurate information over large areas with a high revisit frequency [
                <xref ref-type="bibr" rid="B62-remotesensing-10-00641">62</xref>
                ]. UAS platforms provide one such technology that is enabling new horizons in vegetation monitoring. For instance, the high resolution of UAS imagery has led to a significant increase in the overall accuracy in species-level vegetation classification, monitoring vegetation status, weed infestations, estimating biomass, predicting yields, detecting crop water stress and/senescent leaves, reviewing herbicide applications, and pest control.
            </p>
                  
            <sec id="sec3dot1-remotesensing-10-00641">
                        
                <title>3.1. Vegetation Monitoring and Precision Agriculture</title>
                        
                <p>
                    Precision agriculture [
                    <xref ref-type="bibr" rid="B63-remotesensing-10-00641">63</xref>
                    ] has been the most common environmental monitoring application of UAS. High-spatial-resolution UAS imagery enables much earlier and more cost-effective detection, diagnosis, and corrective action of agricultural management problems compared to low-resolution satellite imagery. Therefore, UAS may provide the required information to address the needs of farmers or other users at the field scale, enabling them to make better management decisions with minimal costs and environmental impact [
                    <xref ref-type="bibr" rid="B64-remotesensing-10-00641">64</xref>
                    ,
                    <xref ref-type="bibr" rid="B65-remotesensing-10-00641">65</xref>
                    ,
                    <xref ref-type="bibr" rid="B66-remotesensing-10-00641">66</xref>
                    ].
                </p>
                        
                <p>
                    Vegetation state can be evaluated and quantified through different vegetation indices from images acquired in the visible, red edge, and near-infrared spectral bands. Depending on their formulation, these can display a strong correlation with soil coverage and Leaf and Green Area Index (LAI and GAI), Crop Nitrogen Uptake (QN), chlorophyll content, water stress detection, canopy structure, photosynthesis, yield, and/or growing conditions [
                    <xref ref-type="bibr" rid="B67-remotesensing-10-00641">67</xref>
                    ,
                    <xref ref-type="bibr" rid="B68-remotesensing-10-00641">68</xref>
                    ,
                    <xref ref-type="bibr" rid="B69-remotesensing-10-00641">69</xref>
                    ]. As such, these vegetation indices may be exploited to monitor biophysical parameters.
                </p>
                        
                <p>
                    Among the many available vegetation indices, the Normalized Difference Vegetation Index (NDVI) is one that is most widely used [
                    <xref ref-type="bibr" rid="B70-remotesensing-10-00641">70</xref>
                    ,
                    <xref ref-type="bibr" rid="B71-remotesensing-10-00641">71</xref>
                    ,
                    <xref ref-type="bibr" rid="B72-remotesensing-10-00641">72</xref>
                    ]. UAS-NDVI maps can be at least comparable to those obtained from satellite visible observations and become highly relevant for a timely assessment of crop health status, with capacity to provide immediate feedback to the farmer. NDVI surveys performed with UAS, aircraft, and satellite demonstrate that low-resolution images generally fail in representing intrafield variability and patterns in fields characterized by small vegetation gradients and high vegetation patchiness [
                    <xref ref-type="bibr" rid="B7-remotesensing-10-00641">7</xref>
                    ]. Moreover, UAS-derived NDVIs have shown better agreement with ground-based NDVI observations compared to satellite-derived NDVIs in several crop and natural vegetation types [
                    <xref ref-type="bibr" rid="B73-remotesensing-10-00641">73</xref>
                    ,
                    <xref ref-type="bibr" rid="B74-remotesensing-10-00641">74</xref>
                    ,
                    <xref ref-type="bibr" rid="B75-remotesensing-10-00641">75</xref>
                    ]. As an example of the achievable resolution that can be obtained from UAVs, relative to some available high-resolution commercial satellite sensors, 
                    <xref ref-type="fig" rid="remotesensing-10-00641-f003">Figure 3</xref>
                     shows a multi-sensor sequence of imagery collected over a date palm plantation in Saudi Arabia. The observed differences between vegetation patterns and resolvable resolution observed by UAS (compared to available satellite platforms) are clearly identified. The relative advantages of UAS in providing a level of detail that is comparable to field observations (or in deriving NDVI or other related vegetation indices for more in depth assessment) is illustrated by its capability of capturing both within and between canopy behavior.
                </p>
                        
                <p>
                    In the last decade, particular attention has been given to the monitoring of vineyards because of their high economic value. Johnson et al. [
                    <xref ref-type="bibr" rid="B76-remotesensing-10-00641">76</xref>
                    ] proposed one of the first applications where different sensors were used for determining measures related to chlorophyll function and photosynthetic activity, LAI, and plant health status (among other variables) to mapping vigor differences within fields. More recently, Zarco-Tejada et al. [
                    <xref ref-type="bibr" rid="B52-remotesensing-10-00641">52</xref>
                    ,
                    <xref ref-type="bibr" rid="B77-remotesensing-10-00641">77</xref>
                    ,
                    <xref ref-type="bibr" rid="B78-remotesensing-10-00641">78</xref>
                    ,
                    <xref ref-type="bibr" rid="B79-remotesensing-10-00641">79</xref>
                    ,
                    <xref ref-type="bibr" rid="B80-remotesensing-10-00641">80</xref>
                    ] demonstrated the potential for monitoring specific variables such as crop water stress index, photosynthetic activity, and carotenoid content in vineyards using multispectral, hyperspectral, and thermal cameras.
                </p>
                        
                <p>
                    Based upon author experiences, farmers have expressed particular interest in monitoring crop conditions for the quantification of water demand, nitrogen status, or infestation treatments. Several of the variables or indices described above may be used for rapid detection of crop pest outbreaks or for mapping the status of crops. Likewise, monitoring soil water content is critical for determining efficient irrigation scheduling. The topsoil moisture content can be derived using RGB, NIR, and thermal bands [
                    <xref ref-type="bibr" rid="B81-remotesensing-10-00641">81</xref>
                    ]. The effective amount of water stored in the subsurface can be obtained by exploiting mathematical relationships between surface measurements and the root zone soil moisture, such as the Soil Moisture Analytical Relationship (SMAR) [
                    <xref ref-type="bibr" rid="B82-remotesensing-10-00641">82</xref>
                    ,
                    <xref ref-type="bibr" rid="B83-remotesensing-10-00641">83</xref>
                    ].
                </p>
                        
                <p>
                    As a further example, Sullivan et al. [
                    <xref ref-type="bibr" rid="B84-remotesensing-10-00641">84</xref>
                    ] observed that the thermal infrared (TIR) emittance was highly sensitive to canopy state and can be used for monitoring soil water content, stomatal conductance, and canopy cover. TIR has similarly been used for the monitoring and estimation of soil surface characteristics such as microrelief and rill morphology [
                    <xref ref-type="bibr" rid="B85-remotesensing-10-00641">85</xref>
                    ], soil water repellency [
                    <xref ref-type="bibr" rid="B86-remotesensing-10-00641">86</xref>
                    ], soil surface macropores [
                    <xref ref-type="bibr" rid="B87-remotesensing-10-00641">87</xref>
                    ], skin surface soil permeability [
                    <xref ref-type="bibr" rid="B88-remotesensing-10-00641">88</xref>
                    ], and overland and rill flow velocities by using thermal tracers [
                    <xref ref-type="bibr" rid="B89-remotesensing-10-00641">89</xref>
                    ,
                    <xref ref-type="bibr" rid="B90-remotesensing-10-00641">90</xref>
                    ].
                </p>
                        
                <p>
                    More specifically, the TIR emittance displays a negative correlation with stomatal conductance and canopy closure, indicating increasing canopy stress as stomatal conductance and canopy closure decreased. The crop water stress index (CWSI) [
                    <xref ref-type="bibr" rid="B91-remotesensing-10-00641">91</xref>
                    ,
                    <xref ref-type="bibr" rid="B92-remotesensing-10-00641">92</xref>
                    ] calculated from leaf water potential can be used to determine the required frequency, timing, and duration of watering. In this regard, the CWSI, derived with a UAS equipped with a thermal camera, is frequently adopted to quantify the physiological status of plants, and, more specifically, leaf water potential in experimental vineyards or orchards [
                    <xref ref-type="bibr" rid="B52-remotesensing-10-00641">52</xref>
                    ,
                    <xref ref-type="bibr" rid="B80-remotesensing-10-00641">80</xref>
                    ,
                    <xref ref-type="bibr" rid="B93-remotesensing-10-00641">93</xref>
                    ,
                    <xref ref-type="bibr" rid="B94-remotesensing-10-00641">94</xref>
                    ,
                    <xref ref-type="bibr" rid="B95-remotesensing-10-00641">95</xref>
                    ,
                    <xref ref-type="bibr" rid="B96-remotesensing-10-00641">96</xref>
                    ]. The derived CWSI maps can serve as important inputs for precision irrigation. Time series of thermal images can also be used to determine the variation in water status [
                    <xref ref-type="bibr" rid="B97-remotesensing-10-00641">97</xref>
                    ].
                </p>
                        
                <p>
                    Using VIS–NIR (400–1000 nm) hyperspectral and multispectral analyses of simulated data has shown that soil attributes can be extracted from these spectral regions, particularly those most commonly used by the current UAS platforms [
                    <xref ref-type="bibr" rid="B98-remotesensing-10-00641">98</xref>
                    ,
                    <xref ref-type="bibr" rid="B99-remotesensing-10-00641">99</xref>
                    ,
                    <xref ref-type="bibr" rid="B100-remotesensing-10-00641">100</xref>
                    ]. These studies demonstrated that the VIS-NIR spectral region alone can open up new frontiers in soil mapping (as well as soil moisture content retrieval) using on-board multi- and hyperspectral UAS sensors without using heavyweight sensors operating in the SWIR (1–2.5 μm) region. Aldana-Jague et al. [
                    <xref ref-type="bibr" rid="B32-remotesensing-10-00641">32</xref>
                    ] mapped soil surface organic carbon content (&lt;0.5 cm) at 12 cm resolution exploiting six bands between 450 and 1050 nm acquired by low-altitude multispectral imagers. D’Oleire-Oltmanns et al. [
                    <xref ref-type="bibr" rid="B30-remotesensing-10-00641">30</xref>
                    ] showed the applicability of UAS for measuring, mapping, and monitoring soil erosion at 5 cm resolution with an accuracy between 0.90 and 2.7 cm in the horizontal and 0.70 cm in the vertical directions. Detailed information about soil erosion can enhance proper soil management at the plot scale [
                    <xref ref-type="bibr" rid="B31-remotesensing-10-00641">31</xref>
                    ].
                </p>
                        
                <p>
                    Such tools were further explored by Zhu et al. [
                    <xref ref-type="bibr" rid="B22-remotesensing-10-00641">22</xref>
                    ], who investigated the ability to quantify the differences in soil nitrogen application rates using digital images taken from a UAS compared with ground-based hyperspectral reflectance and chlorophyll content data. They suggested that aerial photography from a UAS has the potential to provide input in support of crop decision-making processes, minimizing field sampling efforts, saving both time and money, and enabling accurate assessment of different nitrogen application rates. Therefore, such information may serve as input to other agricultural systems, such as tractors or specific UAS, that optimize fertilizer management.
                </p>
                        
                <p>
                    UAS can also improve agronomical practices. Costa et al. [
                    <xref ref-type="bibr" rid="B101-remotesensing-10-00641">101</xref>
                    ] described an architecture that can be employed to implement a control loop for agricultural applications where UAS are responsible for spraying chemicals on crops. Application of chemicals is controlled by the feedback obtained from a wireless sensor network (WSN) deployed on the crop field. They evaluated an algorithm to adjust the UAS route under changes in wind (intensity and direction) to minimize the waste of pesticides. Peña et al. [
                    <xref ref-type="bibr" rid="B102-remotesensing-10-00641">102</xref>
                    ,
                    <xref ref-type="bibr" rid="B103-remotesensing-10-00641">103</xref>
                    ] explored the optimization of herbicide applications in weed–crop systems using a series of UAS multispectral images. The authors computed multiple data, which permitted both calculation of herbicide requirements and estimation of the overall cost of weed management operations in advance. They showed that the ability to discriminate weeds was significantly affected by the imagery spectra (type of camera) used as well as the spatial (flight altitude) and temporal (the date of the study) resolutions.
                </p>
                        
                <p>
                    Among these technical advantages and constraints, the importance of the limitation of operational rules in using UAS in several countries needs to be highlighted. As an example, Jeunnette and Hart [
                    <xref ref-type="bibr" rid="B24-remotesensing-10-00641">24</xref>
                    ] developed a parametric numerical model to compare aerial platform options (UAS vs airborne) to support agriculture in developing countries characterized by highly fragmented fields, but manned systems are still more competitive from an operational and cost/efficiency point of view because of the present limitations in altitude, distance, and speed of UAS. In particular, UAS become cost-competitive when they are allowed to fly higher than 300 m AGL (above ground level), while current limits are set around 120–150 m. This is a critical limitation for the use of UAS along with the fact that flights should be within visible line of sight (VLOS) in many jurisdictions.
                </p>
                        
                <p>All the applications described highlight the potential use of UAS in developing advanced tools for precision agriculture applications and for vegetation monitoring in general. With time, both technological advances and legislation will evolve and likely converge, further advancing the efficient use of such technologies.</p>
                      
            </sec>
                  
            <sec id="sec3dot2-remotesensing-10-00641">
                        
                <title>3.2. Monitoring of Natural Ecosystems</title>
                        
                <p>
                    As with agricultural ecosystems, the proliferation of UAS-based remote sensing techniques has opened up new opportunities for monitoring and managing natural ecosystems [
                    <xref ref-type="bibr" rid="B12-remotesensing-10-00641">12</xref>
                    ,
                    <xref ref-type="bibr" rid="B104-remotesensing-10-00641">104</xref>
                    ,
                    <xref ref-type="bibr" rid="B105-remotesensing-10-00641">105</xref>
                    ,
                    <xref ref-type="bibr" rid="B106-remotesensing-10-00641">106</xref>
                    ]. In fact, UAS provides options and opportunities to collect data at appropriate spatial and temporal resolutions to describe ecological processes and allow better surveying of natural ecosystems placed in remote, inaccessible, or difficult- and/or dangerous-to-access sites. As examples, some habitats (e.g., peat bogs) can be damaged through on-ground surveys, while UAS positioned several meters above the surface can provide a near-comparable level of information as that obtained through plot-based measurements (e.g., canopy cover by species). UAS are also useful for undertaking rapid surveys of habitats such as mangroves, where access is often difficult and plot-based surveys take far longer to complete (see 
                    <xref ref-type="fig" rid="remotesensing-10-00641-f004">Figure 4</xref>
                    ). 
                </p>
                        
                <p>
                    UAS therefore offer the potential to overcome these limitations and have been applied to monitor a disparate range of habitats and locations, including tropical forests, riparian forests, dryland ecosystems, boreal forests, and peatlands. Pioneering researchers have been using UAS to monitor attributes such as plant population [
                    <xref ref-type="bibr" rid="B107-remotesensing-10-00641">107</xref>
                    ,
                    <xref ref-type="bibr" rid="B108-remotesensing-10-00641">108</xref>
                    ]; biodiversity and species richness [
                    <xref ref-type="bibr" rid="B109-remotesensing-10-00641">109</xref>
                    ,
                    <xref ref-type="bibr" rid="B110-remotesensing-10-00641">110</xref>
                    ]; plant species invasion [
                    <xref ref-type="bibr" rid="B111-remotesensing-10-00641">111</xref>
                    ]; restoration ecology [
                    <xref ref-type="bibr" rid="B112-remotesensing-10-00641">112</xref>
                    ]; disturbances [
                    <xref ref-type="bibr" rid="B113-remotesensing-10-00641">113</xref>
                    ]; phenology [
                    <xref ref-type="bibr" rid="B114-remotesensing-10-00641">114</xref>
                    ]; pest infestation in forests [
                    <xref ref-type="bibr" rid="B115-remotesensing-10-00641">115</xref>
                    ,
                    <xref ref-type="bibr" rid="B116-remotesensing-10-00641">116</xref>
                    ]; and land cover change [
                    <xref ref-type="bibr" rid="B117-remotesensing-10-00641">117</xref>
                    ].
                </p>
                        
                <p>
                    Many studies have focused on the retrieval of vegetation structural information to support forest assessment and management [
                    <xref ref-type="bibr" rid="B118-remotesensing-10-00641">118</xref>
                    ,
                    <xref ref-type="bibr" rid="B119-remotesensing-10-00641">119</xref>
                    ]. For instance, information on the plant and canopy height can be obtained from stereo images [
                    <xref ref-type="bibr" rid="B120-remotesensing-10-00641">120</xref>
                    ,
                    <xref ref-type="bibr" rid="B121-remotesensing-10-00641">121</xref>
                    ], which can be used to estimate above-ground biomass (see for example 
                    <xref ref-type="fig" rid="remotesensing-10-00641-f004">Figure 4</xref>
                    ). 3D maps of canopy can also be used to distinguish between trunks, branches, and foliage [
                    <xref ref-type="bibr" rid="B121-remotesensing-10-00641">121</xref>
                    ].
                </p>
                        
                <p>
                    UAS represent a promising option enabling timely, fast, and precise monitoring that is important for many plant species, particularly those that are invasive [
                    <xref ref-type="bibr" rid="B122-remotesensing-10-00641">122</xref>
                    ,
                    <xref ref-type="bibr" rid="B123-remotesensing-10-00641">123</xref>
                    ,
                    <xref ref-type="bibr" rid="B124-remotesensing-10-00641">124</xref>
                    ]. Flexibility of the data acquisition enabled by the UAS is very important, since plants are often more distinct from the surrounding vegetation in certain times of their growing season [
                    <xref ref-type="bibr" rid="B125-remotesensing-10-00641">125</xref>
                    ]. Besides rapid monitoring of newly invaded areas, the UAS methodology enables prediction/modelling of invasion spread that can be driven by a combination of factors, such as habitat and species characteristics, human dispersal, and disturbances [
                    <xref ref-type="bibr" rid="B126-remotesensing-10-00641">126</xref>
                    ]. Legal constraints limiting the use of UAS to unpopulated areas can be especially problematic for monitoring invasive species that tend to prefer urban areas. Still, the UAS technology can greatly reduce costs of extensive field campaigns and eradication measures [
                    <xref ref-type="bibr" rid="B127-remotesensing-10-00641">127</xref>
                    ].
                </p>
                        
                <p>
                    UAS are also revolutionizing the management of quasi-natural ecosystems, such as restored habitats and managed forests. They have been used to quantify spatial gap patterns in forests in order to support the planning of common forest management practices such as thinning [
                    <xref ref-type="bibr" rid="B128-remotesensing-10-00641">128</xref>
                    ] or to support restoration monitoring. For example, Quilter et al. [
                    <xref ref-type="bibr" rid="B129-remotesensing-10-00641">129</xref>
                    ] used UAS for monitoring streams and riparian restoration projects in inaccessible areas on Chalk Creek (Utah). Knoth et al. [
                    <xref ref-type="bibr" rid="B130-remotesensing-10-00641">130</xref>
                    ] applied a UAS-based NIR remote sensing approach to monitor a restored cut-over bog and Ludovisi et al. [
                    <xref ref-type="bibr" rid="B21-remotesensing-10-00641">21</xref>
                    ] also used TIR data to determine the response of forest to drought in relation to forest tree breeding programs and genetic improvement.
                </p>
                      
            </sec>
                
        </sec>
            
        <sec id="sec4-remotesensing-10-00641">
                  
            <title>4. River Systems and Floods</title>
                  
            <p>
                Satellite data are widely used to monitor natural hazards (e.g., floods, earthquakes, volcanic eruptions, wildfire, etc.) at national and international scales [
                <xref rid="B131-remotesensing-10-00641">131</xref>
                ]. This popularity is due to their wide coverage, spectral resolution, safety, and rate of update [
                <xref rid="B132-remotesensing-10-00641">132</xref>
                ,
                <xref rid="B133-remotesensing-10-00641">133</xref>
                ]. Nevertheless, UAS have also been adopted for rapid assessment following natural extreme events and in the context of humanitarian relief and infrastructure assessment [
                <xref ref-type="bibr" rid="B28-remotesensing-10-00641">28</xref>
                ]. According to Quaritsch et al. [
                <xref ref-type="bibr" rid="B134-remotesensing-10-00641">134</xref>
                ], UAS should be utilized as a component of a network of sensors for natural disaster management. Although there are a number of technological barriers, which must be overcome before UAS can be utilized in a more automated and coordinated manner, their potential for disaster response is significant [
                <xref ref-type="bibr" rid="B135-remotesensing-10-00641">135</xref>
                ]. Given the UAS potential, we expect significant advances in the fields of hydrology, geomorphology, and hydraulics, where there is a significant opportunity for the use of UAS for monitoring river systems, overland flows, or even urban floods.
            </p>
                  
            <sec id="erc:inherit=delete">
                        
                <title>Flow Monitoring</title>
                        
                <p>
                    River systems and stream flows can be monitored by remotely integrating the techniques of water body observation, vegetation mapping, DEM generation, and hydrological modelling. Satellite sensors in the visible, infrared, and microwave ranges are currently used to monitor rivers and to delineate flood zones [
                    <xref rid="B136-remotesensing-10-00641">136</xref>
                    ,
                    <xref rid="B137-remotesensing-10-00641">137</xref>
                    ,
                    <xref rid="B138-remotesensing-10-00641">138</xref>
                    ]. These methods are generally used only over large rivers or areas of inundation in order to detect changes at the pixel level. UAS can describe river dynamics, but with a level of detail that is several orders of magnitude greater and can enable distributed flow measurements over any river system and in difficult-to-access environments.
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                </p>
                        
                <p>
                    In this context, the integration of UAS imagery and optical velocimetry techniques has enabled full remote kinematic characterization of water bodies and surface flows. Optical techniques, such as Large-Scale Particle Image Velocimetry (LSPIV, [
                    <xref rid="B139-remotesensing-10-00641">139</xref>
                    ]) and Particle Tracking Velocimetry (PTV [
                    <xref rid="B140-remotesensing-10-00641">140</xref>
                    ]), are efficient yet nonintrusive flow visualization methods that yield a spatially distributed estimation of the surface flow velocity field based on the similarity of image sequences. Proof-of-concept experiments have demonstrated the feasibility of applying LSPIV from manned aerial systems to monitor flood events [
                    <xref rid="B141-remotesensing-10-00641">141</xref>
                    ,
                    <xref ref-type="bibr" rid="B142-remotesensing-10-00641">142</xref>
                    ]. More recently, videos recorded from a UAS have been analyzed with LSPIV to reconstruct surface flow velocity fields of natural stream reaches [
                    <xref ref-type="bibr" rid="B143-remotesensing-10-00641">143</xref>
                    ,
                    <xref ref-type="bibr" rid="B144-remotesensing-10-00641">144</xref>
                    ]. This provides a detailed Lagrangian insight into river dynamics that is valuable in calibrating numerical models. 
                </p>
                        
                <p>
                    Most of these experimental observations entail a low-cost UAS hovering above the region of interest for a few seconds (the observation time should be adjusted to the flow velocity and camera acquisition frequency). An RGB camera is typically mounted onboard and installed with its optical axis perpendicular to the captured field of view to circumvent orthorectification [
                    <xref rid="B145-remotesensing-10-00641">145</xref>
                    ]. To facilitate remote photometric calibration, Tauro et al. [
                    <xref rid="B145-remotesensing-10-00641">145</xref>
                    ] adopted a UAS equipped with a system of four lasers that focus points at known distances in the field of view. In several experimental settings, the accuracy of surface flow velocity estimations from UAS was found to be comparable to (or even better than) that of traditional ground-based LSPIV configurations [
                    <xref rid="B146-remotesensing-10-00641">146</xref>
                    ]. In fact, compared to fixed implementations, UAS enable capture of larger fields of view with a diffuse rather than direct illumination. Such optical image velocimetry techniques can measure flow velocity fields over extended regions rather than pointwise, and at temporal resolutions comparable to or even better than Acoustic Doppler Velocimetry (ADV) based on the presence of detectable features on the water surface [
                    <xref rid="B147-remotesensing-10-00641">147</xref>
                    ].
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                </p>
                        
                <p>
                    In this context, UAS technology is expected to considerably aid in flood monitoring and mapping. In fact, flood observation is a considerable challenge for space-borne passive imagery, mostly due to the presence of dense cloud cover, closed vegetation canopies, and the satellite revisit time and viewing angle [
                    <xref rid="B133-remotesensing-10-00641">133</xref>
                    ,
                    <xref rid="B148-remotesensing-10-00641">148</xref>
                    ]. Although SAR satellite sensors (e.g., Sentinel-1, TerraSAR-X, RADARSAT-2) can overcome these visibility limitations, they are unable to provide the submeter-level spatial resolution necessary for detailed understanding of flood routing and susceptibility. Applying UAS with an appropriate flight mode may overcome some of these issues, allowing for rapid and safe monitoring of inundations and measurement of flood hydrological parameters [
                    <xref rid="B149-remotesensing-10-00641">149</xref>
                    ]. This is possible also because most platforms are quite stable in windy conditions (less than 5 m/s in the case of multirotors).
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                </p>
                        
                <p>
                    Challenges for the widespread adoption and incorporation of UAS for flow monitoring have commonalities with both agricultural and ecosystems monitoring, including the coupling of measurements from multiple sensors through accurate and efficient processing workflows. Specific to streamflow measurement, these include (i) optimization of SfM workflows to enable extraction of terrestrial and subsurface topographies through accurate image registration using automatic or direct georeferencing techniques; (ii) the determination of water levels through image- (e.g., SfM; [
                    <xref rid="B150-remotesensing-10-00641">150</xref>
                    ]), sensor- (e.g., laser, radar; [
                    <xref rid="B151-remotesensing-10-00641">151</xref>
                    ]), and turbulence-derived metrics [
                    <xref rid="B152-remotesensing-10-00641">152</xref>
                    ]; and (iii) the derivation of flow velocities through appropriate techniques (e.g., PIV/PTV), based on the characteristics of flow, duration of observation, seeding density, etc.). The task of combining these data and developing workflows that are capable of rapidly producing synoptic river flow measurements based on the range of available inputs is an ongoing challenge to ensure UAS-based measurements are able to fully support water resource management and civil protection agencies.
                </p>
                        
                <p>
                    In this context, hyperspectral sensors can also be used to extend the range of water monitoring applications. Potential examples include sediment concentration, chlorophyll distribution, blooming algae status, submerged vegetation mapping, bathymetry, and chemical and organic waste contaminations [
                    <xref rid="B153-remotesensing-10-00641">153</xref>
                    ,
                    <xref rid="B154-remotesensing-10-00641">154</xref>
                    ].
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                    <xref erc:inherit="delete"/>
                    [erc:inherit=delete]
                </p>
                        
                <p erc:inherit="delete"/>
                        
                <p erc:inherit="delete"/>
                        
                <p erc:inherit="delete"/>
                        
                <p erc:inherit="delete"/>
                        
                <p erc:inherit="delete"/>
                        
                <p erc:inherit="delete"/>
                      
            </sec>
                  
            <sec erc:inherit="delete"/>
                
        </sec>
            
        <sec id="sec5-remotesensing-10-00641">
                  
            <title>5. Final Remarks and Challenges</title>
                  
            <p>
                UAS-based remote sensing provides new advanced procedures to monitor key variables, including vegetation status, soil moisture content, and stream flow. A detailed description of such variables will increase our capacity to describe water resource availability and assist agricultural and ecosystem management. Our manuscript provides an overview of some of the recent applications in field-based UAS surficial environmental monitoring. The wide range of applications testifies to the great potential of these techniques, but, at the same time, the variety of methodologies adopted is evidence that there is still need for harmonization efforts. The variety of available platforms, sensors, and specificity of any particular case study have stimulated a proliferation of a huge number of specific algorithms addressing flight planning, image registration, calibration and correction, and derivation of indices or variables. However, there is no evidence of comprehensive comparative studies that enable the user to select the most appropriate procedure for any specific need.
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
                <xref erc:inherit="delete"/>
                [erc:inherit=delete]
            </p>
                  
            <sec erc:inherit="delete"/>
                  
            <p>
                A review of the literature carried out herein allowed the identification of a number of outstanding issues in the use of UAS for environmental monitoring. Among others, we selected the following that require specific attention:
                <list list-type="roman-lower">
                    <list-item>
                        <label>(i)</label>
                        <p>While a direct comparison between different methodologies (UAS, manned airborne, and satellite) is challenging, it was found that UAS systems represent a cost-effective monitoring technique over small regions (&lt;20 ha). For larger extents, manned airborne or satellite platforms may become more effective options, but only when the temporal advantage of the UAS is not considered.</p>
                    </list-item>
                    <list-item>
                        <label>(ii)</label>
                        <p>The limited extent of the studied areas reduces the relative budget available, increasing the fragmentation of the adopted procedures and methodologies.</p>
                    </list-item>
                    <list-item>
                        <label>(iii)</label>
                        <p>Government regulations restricting the Ground Sample Distance (GSD) and the UAS flight mode are limiting the economic advantages related to their use and some potential applications, particularly in urban environments.</p>
                    </list-item>
                    <list-item>
                        <label>(iv)</label>
                        <p>The wide range of experiences described highlighted the huge variability in the strategies, methodologies, and sensors adopted for each specific environmental variable monitored. This identifies the need to find unifying principles in UAS-based studies.</p>
                    </list-item>
                    <list-item>
                        <label>(v)</label>
                        <p>Vulnerability of UAS to weather conditions (e.g., wind, rain) can alter quality of the surveys.</p>
                    </list-item>
                    <list-item>
                        <label>(vi)</label>
                        <p>
                            There are also technical limits, such as weather constraints (strong wind and/or rain), high elevations, or high-temperature environments that can be challenging for most of the devices/sensors and respective UAS operators (see, e.g., [
                            <xref ref-type="bibr" rid="B155-remotesensing-10-00641">155</xref>
                            ]).
                        </p>
                    </list-item>
                    <list-item>
                        <label>(vii)</label>
                        <p>The geometric and radiometric limitations of current lightweight sensors make the use of this technology challenging.</p>
                    </list-item>
                    <list-item>
                        <label>(viii)</label>
                        <p>The high spatial resolution of UAS data generates high demand on data storage and processing capacity.</p>
                    </list-item>
                    <list-item>
                        <label>(ix)</label>
                        <p>There is a clear need for procedures to characterize and correct the sensor errors that can propagate in the subsequent mosaicking and related data processing.</p>
                    </list-item>
                    <list-item>
                        <label>(x)</label>
                        <p>Finally, a disadvantage in the use of UAS is represented by the complexity associated to their use that is comparable to that of satellites. In fact, satellite applications are generally associated to a chain of processing assuring the final quality of data. In the case of UAS, all this is left to the final user or researcher, requiring additional steps in order to be able to use the retrieved data.</p>
                    </list-item>
                </list>
            </p>
                  
            <p>
                It should be recognized that the UAS sector has received much less funding to address the existing gaps in technology and processing chains needed to produce useable images than, for instance, satellite-based programs (
                <xref ref-type="fig" rid="remotesensing-10-00641-f005">Figure 5</xref>
                ). However, this is one of the reasons why there is much potential for further improvements in the technology and its use. One particular benefit of UAV improvements is related to the potential benefit that could be directed towards satellite-based observations, which can leverage the utilization of highly detailed UAS data. Given the spatiotemporal advantage of UAS systems, they can provide much higher return periods, offering several flights per day to study very dynamic processes at high spatial resolution, such as physiological response of vegetation to heat or even rapid flooding events. The combination of these data allows an advanced satellite test-bed for examining scale effects due to spatial resolution, identifying the most suitable acquisition time, establishing the effects of temporal resolution, incorporating suitable spectral bands, and establishing needed radiometric resolution, etc., all of which provide feedback to developing improved space-borne platforms in a way that ground-based monitoring alone can never replicate. Moreover, the capability to achieve a resolution comparable with the scale of field measurements gives the opportunity to address the issue of within-pixel spatial heterogeneity observed by satellites.
            </p>
                  
            <p>
                With time, natural selection will likely deliver the most efficient collection and processing solutions for different contexts and applications, but there is still a significant amount of work needed to drive this change. Therefore, a major challenge for the scientific community is to foster this process by providing some guidance in the wide range of possibilities offered by the market. On the other side of this, the private sector of UAS developers are also investing in this field, accelerating the evolution of the technology. Among the many advances, it is interesting to mention the following:
                <list list-type="bullet">
                    <list-item>
                        <p>
                            One of the aspects directly impacting the area that is able to be sensed is the limited flight times of UAS. This problem is currently managed by mission planning that enables management of multiple flights. Technology is also offering new solutions that will extend the flight endurance up to several hours, making the use of UAS more competitive. For instance, new developments in batteries suggest that the relatively short flying time imposed by current capacity will be significantly improved in the future [
                            <xref ref-type="bibr" rid="B156-remotesensing-10-00641">156</xref>
                            ]. In this context, another innovation introduced in the most recent vehicles is an integrated energy supply system connected with onboard solar panels that allow flight endurance to be extended from 40–50 min up to 5 h, depending on the platform.
                        </p>
                    </list-item>
                    <list-item>
                        <p>The relative ground sampling distance affects the quality of the surveys, but is often not compensated for. This limitation can now be solved by implementing 3D flight paths that follow the surface in order to maintain a uniform GSD. Currently, only a few software suites (e.g., UgCS, eMotion 3) use digital terrain models to adjust the height path of the mission in order to maintain consistent GSD.</p>
                    </list-item>
                    <list-item>
                        <p>The influence of GSD may be reduced by increasing flight height, making UAS even more cost-competitive (by increasing sensed areas), but current legislation in many jurisdictions limits this to between 120 and 150 m and to within visible line of sight (VLOS). In this context, the development of microdrones will significantly reduce risk associated with their use, and relax some of the constraints due to safety requirements.</p>
                    </list-item>
                    <list-item>
                        <p>Recent and rapid developments in sensor miniaturization, standardization, and cost reduction have opened new possibilities for UAS applications. However, limits remain, especially for commercial readymade platforms that are used the most among the scientific community.</p>
                    </list-item>
                    <list-item>
                        <p>Sensor calibration remains an issue, especially for hyperspectral sensors. For example, vegetation can be measured in its state and distribution using RGB, multispectral, hyperspectral, and thermal cameras, as well as with LiDAR.</p>
                    </list-item>
                    <list-item>
                        <p>Image registration, correction, and calibration remain major challenges. The vulnerability of UAS to weather conditions (wind, rain) and the geometric and radiometric limitations of current lightweight sensors have stimulated the development of new algorithms for image mosaicking and correction. In this context, the development of open source and commercial SfM software allows image mosaicking to be addressed, but radiometric correction and calibration is still an open question that may find a potential solution through experience with EO. Moreover, the development of new mapping-quality cameras has already significantly improved spatial registration and will likely help to also improve the overall quality of the UAS imagery.</p>
                    </list-item>
                </list>
            </p>
                  
            <p>Technological advances are strongly supporting the diffusion of these technologies over a wide range of fields, including hydrology. On the other hand, the research community must address significant challenges in standardizing the methodologies adopted. All environmental variables (e.g., vegetation, soil moisture, and river flow) can be measured using different sensors and algorithms, but a comprehensive assessment of the performances of each of these methods and procedures is required. Such efforts may help to improve our capacity in describing the spatiotemporal processes at both the field and the river basin scale. Moreover, UAS technology can be easily integrated with other devices and tools (cell phone, fixed installations, etc.), allowing advances in agricultural practices and hydrometeorological monitoring. </p>
                  
            <p>
                Technology and scientific research have a clear path to follow that has already (largely) been traced by manned aerial photogrammetry and Earth observation from satellites. In fact, current observational practices have already addressed several of the problems that UAS-based observations are facing (e.g., image mosaicking, sensor calibration, radiometric calibration, etc.). Nevertheless, the ensemble of such problems connected to the proper use of UAS introduces a data processing complexity that is comparable to or slightly larger than that of satellites (see 
                <xref ref-type="fig" rid="remotesensing-10-00641-f005">Figure 5</xref>
                ) and makes their use difficult even for an experienced scientist without clear guidance.
            </p>
                  
            <p>There is a growing need to define harmonized approaches able to channel the efforts of all these studies and identify the optimal strategy for UAS-based monitoring. The challenge for the research is to define a clear and referenced workflow starting from the planning and acquisition of the data to the generation and interpretation of maps. In particular, we envisage the need to stimulate a comparative experiment able to assess the reliability of different procedures and a combination of algorithms in order to identify the most appropriate methodology for environmental monitoring in different hydroclimatic conditions. The definition of clear and specific procedures may also help in the definition of new legislation at the European scale, removing some of the actual restrictions that limit the potential use of UAS in a wider range of contexts.</p>
                  
            <p>Ultimately, it will be the integration of UAS platforms with different techniques, including traditional instruments, fixed and mobile camera surveys, satellite observations, and geomorphological analyses, that will almost certainly deliver an improved characterization of Earth and environmental systems. Apart from providing improved spatial and temporal coverage, such a strategy of integrated observation will inevitably improve our knowledge of agricultural, hydraulic, geomorphological, ecological, and hydrological dynamics, and provide a basis for advancing our understanding of process description and behavior across space and time scales. </p>
                
        </sec>
            
        <sec erc:inherit="delete"/>
          
    </body>
      
    <back erc:inherit="expand"/>
    
</article>
